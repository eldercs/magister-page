<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ru" lang="ru"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Л. Г. Саетова - Нейронная сеть и регрессия: описание линейной регрессии и нейронных сетях.</title><meta name="author" content="Sveta"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .p, p { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 .s1 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 h1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 h2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s3 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s5 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s6 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s7 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s9 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12.5pt; }
 .s10 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12.5pt; }
 .s11 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s12 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s13 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s14 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: -2pt; }
 .s15 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s16 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 15pt; vertical-align: -2pt; }
 .s17 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s18 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -2pt; }
 .s19 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s20 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s21 { color: black; font-family:Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s22 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -6pt; }
 .s23 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt; }
 .s25 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; vertical-align: -4pt; }
 .s26 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; vertical-align: -4pt; }
 .s28 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s29 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s30 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s31 { color: black; font-family:Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l2 {padding-left: 0pt; }
 #l2> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l3 {padding-left: 0pt;counter-reset: e1 1; }
 #l3> li>*:first-child:before {counter-increment: e1; content: counter(e1, decimal)". "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3> li:first-child>*:first-child:before {counter-increment: e1 0;  }
 li {display: block; }
 #l4 {padding-left: 0pt; }
 #l4> li>*:first-child:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 li {display: block; }
 #l5 {padding-left: 0pt;counter-reset: g1 1; }
 #l5> li>*:first-child:before {counter-increment: g1; content: counter(g1, decimal)". "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l5> li:first-child>*:first-child:before {counter-increment: g1 0;  }
</style></head><body><p style="padding-top: 3pt;padding-left: 32pt;text-indent: 0pt;text-align: center;">Раздел 1. ИНТЕЛЛЕКТУАЛЬНЫЕ ИНФОРМАЦИОННЫЕ ТЕХНОЛОГИИ</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 9pt;padding-left: 32pt;text-indent: 0pt;text-align: center;">Л. Г. Саетова<span class="s2">, аспирант</span></p><p class="s1" style="padding-left: 32pt;text-indent: 0pt;text-align: center;">М. М<span class="s2">. </span>Горохов<span class="s2">, доктор физико-математических наук, профессор Кафедра «Информационные системы»</span></p><p class="s2" style="padding-left: 3pt;text-indent: 0pt;text-align: center;">Ижевский государственный технический университет имени М. Т. Калашникова</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 32pt;text-indent: 0pt;text-align: center;">Нейронная сеть и регрессия:</h1><h1 style="padding-left: 32pt;text-indent: 0pt;text-align: center;">описание линейной регрессии в нейронных сетях</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">В данной статье рассматривается нейронная сеть как способ построе- ния модели для решения таких задач, как установление зависимости и даль- нейшего прогнозирования. Обычно для установления зависимости в мате- матике применяется метод регрессии, т. е. метод нахождения зависимых переменных от независимых с помощью заданной функции. В нейронной се- ти линейная регрессия находит зависимость между входным и выходным сигналом или данными.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">При этом применение нейронной сети для решения задачи регрессии не за- дает конкретный тип нейронной сети, т. е. возможно применение и линейной сети, и многослойного персептрона, и обобщенной регрессионной сети, выбор зависит от решаемой задачи.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">В данной статье рассматривается сама нейронная сеть как способ опре- деления зависимости и возможные функции активации, применяемые при ра- боте нейронной сети, такие как ступенчатая, линейная, сигмоидная, гипербо- лический тангенс, функция ReLu.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">В статье также представлены этапы построения нейронной сети для решения задач линейной регрессии. Установление зависимости между данны- ми необходимо для их анализа и дальнейшего прогнозирования развития. Таким образом, можно представить линейную регрессию в нейронных сетях как мо- дель, которая помогает продолжить ряд данных, установив зависимость между ними.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Ключевые слова: <span class="s2">нейронная сеть, регрессия, линейная регрессия, линей- ная функция активации, сигмоидная функция активации, гиперболический тангенс, функция ReL.</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="192" height="1" alt="image" src="article9_files/Image_001.png"/></span></p><p class="s3" style="padding-top: 3pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">© Саетова Л. Г., Горохов М. М., 2021</p><p class="s1" style="padding-top: 3pt;padding-left: 108pt;text-indent: 0pt;line-height: 10pt;text-align: left;">L. G. Saetova, <span class="s2">Post-graduate</span></p><p class="s1" style="padding-left: 94pt;text-indent: -44pt;text-align: left;">M. M. Gorokhov, <span class="s2">DSc (Physics and Mathematics), Professor Department of Information Systems</span></p><p class="s2" style="padding-left: 72pt;text-indent: 0pt;text-align: left;">Kalashnikov Izhevsk State Technical University</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 71pt;text-indent: -13pt;text-align: left;">Neural Network and Regression: A Description of Linear Regression in Neural Networks</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">This article discusses a neural network as a way to build a model for solving prob- lems such as establishing dependence and further forecasting, usually the regression method is used to establish dependence in mathematics, i.e. method of finding depend- ent variables from independent ones using a given function. In a neural network, linear regression finds the relationship between an input and an output signal or data.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">At the same time, the use of a neural network for solving the regression problem does not specify a specific type of neural network, i.e. it is possible to use a linear network and a multilayer percept and a generalized regression network, the choice depends on the problem being solved.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">This article discusses the neural network itself as a way to determine depend- ence, and possible activation functions used in the operation of a neural network, such as stepwise, linear, sigmoid, hyperbolic tangent, ReLu function.</p><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">This article also presents the stages of building a neural network for solving lin- ear regression problems. Establishing a relationship between data is necessary for their analysis and further forecasting of development. Thus, one can imagine linear regression in neural networks as a model that helps to continue a series of data by establishing a relationship between them.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Keywords: <span class="s2">neural network, regression, linear regression, linear activation func- tion, sigmoid activation function, hyperbolic tangent, ReL function.</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Введение</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">В современном мире сфер применения нейронных сетей большое ко- личество. В науке, экономике и других областях всегда присутствует такая задача, как нахождение связи между данными. Для ее решения обычно применяется модель регрессии. Самая простая из ее видов это линейная регрессия. Цель исследования – рассмотреть нейронную сеть как способ построения регрессионной модели и дальнейшего прогнозирования.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Основные понятия и определения</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Искусственная нейронная сеть является моделью, состоящей из вы- ходного, входного и скрытого слоев, все слои состоят из простейших элементов нейронов.</p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">Нейронные сети состоят из следующих элементов:</p><ul id="l1"><li data-list-text="–"><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">входной сигнал – сигнал, поступающий из внешней среды или другого нейрона, состоит из входных нейронов [1];</p></li><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 14pt;text-align: left;">весовой коэффициент – определяет значение силы связи между нейронами;</p></li><li data-list-text="–"><p style="padding-left: 27pt;text-indent: -7pt;line-height: 12pt;text-align: left;">функция активации – зависимость, преображающая входной сигнал;</p></li><li data-list-text="–"><p style="padding-left: 27pt;text-indent: -7pt;text-align: left;">выходной сигнал – преобразованное значение входного сигнала.</p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Модель и работа нейронной сети</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Нейронная сеть может быть однослойной и многослойной в зави- симости от количества нейронных слоев. Однослойная нейронная сеть представляет собой сеть, в которой входной сигнал проходит только через входной слой, напрямую поступая к выходному слою. Много- слойная нейронная сеть представляет собой нейронную сеть, состоя- щую из входного, выходного и промежуточных слоев, т. е. каждый нейрон сгруппирован в слои, которые связаны между собой нейронами [2], т. е. каждый нейрон на одном слое связан с каждым нейроном на другом слое.</p><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Схематичная модель многослойной нейронной сети представлена на рис. 1.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s2" style="padding-top: 3pt;padding-left: 19pt;text-indent: -7pt;text-align: left;">Входной слой</p><p class="s2" style="padding-top: 3pt;padding-left: 21pt;text-indent: -8pt;text-align: left;">Скрытый слой</p><p class="s2" style="padding-top: 3pt;padding-left: 23pt;text-indent: -11pt;text-align: left;">Выходной слой</p><p style="padding-left: 52pt;text-indent: 0pt;text-align: left;">		</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;text-align: left;"><span><img width="328" height="122" alt="image" src="article9_files/Image_002.png"/></span></p><p class="s1" style="padding-top: 5pt;padding-left: 77pt;text-indent: 0pt;text-align: left;">Рис. 1. <span class="s2">Вид многослойной нейронной сети</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Работа в нейронной сети происходит следующим образом: входной сигнал поступает на входной слой, затем его значения распределяются по весам и поступают на скрытые слои, в которых происходит вычис- ление, и в конце нейроны поступают на выходной слой, формируют выходной вектор [3]. При этом для выбора весовых коэффициентов нейронная сеть должна пройти обучение.</p><p class="s5" style="padding-left: 19pt;text-indent: 0pt;text-align: left;"><span class="s4">Пусть входной сигнал </span>X<span class="s6">i</span> <span class="s7"></span><span class="s8"> </span><span class="s9"></span><span class="s10"> </span>x<span class="s11">1</span><span class="s8">,</span><span class="s7"></span><span class="s8">, </span>x<span class="s6">m</span> <span class="s9"></span><span class="s10"> </span><span class="s12">, а </span>w<span class="s6">i</span> <span class="s7"></span><span class="s8"> </span><span class="s9"></span>w<span class="s11">1</span><span class="s8">,</span><span class="s7"></span><span class="s8">, </span>w<span class="s6">m</span> <span class="s9"></span><span class="s10"> </span><span class="s12">– веса</span></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">входного сигнала. Тогда математическое выражение нейронной сети можно представить в следующем виде:</p><p class="s5" style="padding-top: 4pt;padding-left: 32pt;text-indent: 0pt;text-align: center;">y <span class="s7"></span><span class="s8"> </span>f <span class="s9"></span>u<span class="s6">i</span> <span class="s9"></span><span class="s8">,</span></p><p class="s13" style="padding-left: 32pt;text-indent: 0pt;line-height: 18pt;text-align: center;">u<span class="s14">i </span><span class="s15"></span><span class="p"> </span><span class="s16"></span>w<span class="s14">i </span>x<span class="s14">i </span><span class="s15"></span><span class="p"> </span>b<span class="s14">i </span><span class="p">,</span></p><p class="s17" style="text-indent: 0pt;line-height: 5pt;text-align: center;">i</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">где <i>b</i><span class="s18">i</span></p><ul id="l2"><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 11pt;text-indent: -7pt;text-align: left;">порог активации;</p><p class="s5" style="padding-left: 4pt;text-indent: 0pt;text-align: left;">f <span class="s9"></span>u<span class="s6">i</span> <span class="s9"></span></p></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 10pt;text-indent: -7pt;text-align: left;">передаточная функция или функция</p></li></ul><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">активации, т. е. функция, которая получает на входе сумму всех произ- ведений весов и сигналов и выдает сигнал на выходе [4].</p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 12pt;text-align: left;">Можно представить следующую модель нейрона (рис. 2).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="154" height="132" alt="image" src="article9_files/Image_003.png"/></span></p><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">x<span class="s19">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">w<span class="s19">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">x<span class="s19">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">w<span class="s19">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">x<span class="s19">m</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="text-indent: 0pt;line-height: 10pt;text-align: left;">w<span class="s19">m</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="103" height="8" alt="image" src="article9_files/Image_004.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 43pt;text-indent: 0pt;text-align: center;">y = f(<span class="s19">i</span>)</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">f(u<span class="s19">i</span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 4pt;padding-left: 65pt;text-indent: 0pt;text-align: left;">Рис. 2. <span class="s2">Математическая модель нейронных сетей</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Функции активации</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Функция активации является элементом нейронной сети, ее выбор диктуется необходимыми функциональными возможностями нейрон- ной сети. Выделяют следующие функции активации:</p><ol id="l3"><li data-list-text="1."><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Ступенчатая – пороговая функция активации, значение функции сравнивается с пороговым значением [5], т. е. если функция равна еди- нице, то нейрон активирован. Данный вид функции не подходит для классификации, когда классификаторов больше двух, иными словами, функцию можно применять для бинарной классификации.</p></li><li data-list-text="2."><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Линейная – функция, графиком которой является прямая, зна- чение пропорционально аргументу функции [6]. Позволяет соеди- нить несколько нейронов; если активированы больше одного, то выбирается максимальное значение. Можно применять при боль- шом количестве классификаторов. Область определения не ограни- чена, поэтому не применяется, если выходное значение определено интервалом. Недостатком является невозможность применения ме- тода обратного распространения ошибок, т. к. производная функции активации константа и не зависит от входных значений, также дан- ную функцию бессмысленно применять для многослойных нейрон- ных сетей.</p><p style="padding-top: 3pt;padding-left: 19pt;text-indent: 0pt;text-align: justify;">Функция имеет следющий вид:</p><p class="s5" style="padding-top: 2pt;padding-left: 32pt;text-indent: 0pt;text-align: center;">f <span class="s9"></span>u <span class="s9"></span><span class="s10"> </span><span class="s7"></span><span class="s8"> </span>au <span class="s20">.</span></p></li><li data-list-text="3."><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 14pt;text-align: justify;">Сигмоидная – непрерывная функция, на входе принимает веще- ственные числа, а на выходе дает число [0, 1], где значение ноль гово- рит об отсутствии активации, а единица – о полной активации [7]. Возможно применять для многослойных сетей. Недостатком такой функции является то, что на участках, где функция принимает значе- ния ноля или единицы, градиент будет приближаться к нулю, что озна- чает слабую связь между изменением <span class="s21">f(u) </span>от <span class="s21">u</span>, т. е. нейронная сеть начинает слабо обучаться или перестает обучаться совсем.</p><p style="padding-left: 19pt;text-indent: 0pt;text-align: justify;">Сигмоидная функция:</p><p class="s5" style="padding-top: 7pt;text-indent: 0pt;text-align: right;">f <span class="s9"></span>u <span class="s9"></span><span class="s10"> </span><span class="s7"></span></p><p class="s8" style="padding-top: 5pt;padding-left: 11pt;text-indent: 0pt;line-height: 77%;text-align: left;">1  <span class="s22">.</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="34" height="1" alt="image" src="article9_files/Image_005.png"/></span></p><p class="s8" style="text-indent: 0pt;line-height: 10pt;text-align: left;">1 <span class="s7"></span> <i>e</i><span class="s23"></span><i>u</i></p></li><li data-list-text="4."><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 14pt;text-align: justify;">Гиперболический тангенс – по свойствам напоминает сигмоид- ную функцию, отличие в том, что данная функция работает на отрезке от минус единицы до единицы.</p><p style="padding-left: 19pt;text-indent: 0pt;text-align: justify;">Функция гиперболического тангенса:</p><p class="s5" style="padding-top: 7pt;text-indent: 0pt;text-align: right;">f <span class="s9"></span>u <span class="s9"></span><span class="s10"> </span><span class="s7"></span></p><p class="s8" style="padding-top: 4pt;padding-bottom: 1pt;text-indent: 0pt;text-align: center;">1</p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="article9_files/Image_006.png"/></span></p><p class="s25" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">1 <span class="s26"></span> <i>e</i><span class="s28"></span><span class="s29">2</span><span class="s17">u</span></p><p class="s7" style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><span class="s8">1 </span><span class="s30">.</span></p></li><li data-list-text="5."><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 14pt;text-align: justify;">Функция ReLu – выпрямленная линейная функция активации, функция возвращает значение аргумента, если данное значение не от- рицательно, иначе значение функции равняется нулю [8]. Недостатком является ненадежность в процессе обучения, что может привести к не- активности сети, т. е. нейрон выйдет из строя и прекратит обучение.</p></li></ol><p style="padding-left: 19pt;text-indent: 0pt;text-align: justify;">Функция имеет вид:</p><p class="s9" style="padding-top: 2pt;padding-left: 32pt;text-indent: 0pt;text-align: center;"><span class="s5">f </span><span class="s5">u </span><span class="s10"> </span><span class="s7"></span><span class="s8"> max max </span><span class="s8">0; </span><span class="s5">u </span><span class="s10"> </span><span class="s31">.</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 14pt;text-align: justify;">Количество нейронов при применении данной функции в обучении меньшее, чем при применении функций гиперболического тангенса и сигмоидной, соответственно, сеть тоже становится легче.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Обучение нейронной сети</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">При обучении нейронной сети происходит процесс корректировки весовых коэффициентов и порогов нейрона, для данного процесса за- дается выборка обучающих данных, в процессе обучения нейронная сеть корректирует ответы, приближая их к верным результатам.</p><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Подход к процессу обучения происходит следующим образом: оце- ниваются обучающие данные нейронной сетью, и задается некоторое</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">количество из этих данных для определения точности вычислений. За- тем определяется количество нейронов в каждом слое. После этого идет процесс обучения: во входном слое присваиваются значения всем весам, затем вычисляются выходные значения для каждого обучающе- го варианта и их ошибка, так происходит для каждого значения обу- чающей выборки, затем для минимизации ошибки обновляются весы. Обучение завершается, как только достигается заданная точность.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Линейная регрессия в нейронной сети</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Нейронная сеть является многофункциональным методом прогно- зирования. Так, она может выявлять взаимосвязи между процессами. В математике и статистике для выявления зависимости между данны- ми используется регрессорная зависимость, которая может быть как линейной, так и логистической (нелинейной), которая накладывает ог- раничения значений в виде отрезка от нуля до единицы.</p><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Общую модель решения задачи линейной регрессии в нейронной сети можно представить в следующем виде:</p><ul id="l4"><li data-list-text=""><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">генерируются элементы данных, необходимых для обучения мо- дели;</p></li><li data-list-text=""><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">создается нейронная сеть, содержащая входной, выходной и скрытые слои;</p></li><li data-list-text=""><p style="padding-left: 27pt;text-indent: -7pt;line-height: 12pt;text-align: justify;">задается функция активации для скрытого слоя;</p></li><li data-list-text=""><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">начинается обучение нейронной сети, т. е. находятся коэффици- енты весов, которые дадут более верные результаты, построенные на известных результатах обучающей выборки;</p></li><li data-list-text=""><p style="padding-left: 27pt;text-indent: -7pt;text-align: justify;">выдаются выходные значения;</p></li><li data-list-text=""><p style="padding-left: 27pt;text-indent: -7pt;text-align: justify;">оценивается модель.</p></li></ul><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">В линейной регрессии нейронной сети в большинстве случаев бы- вает несколько входных узлов и один выходной узел.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Анализ результатов</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Линейная модель в нейронных сетях представляет собой сеть, не со- держащую в себе скрытых слоев, и элементы с линейной функцией акти- вации на выходном слое, где выходной сигнал показывает ожидаемое зна- чение модели, в которой учитывается плотность распределения данных.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Вывод</h1><p style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Таким образом, для применения линейной модели регрессии в ней- ронных сетях нужно загрузить данные, создать модели и приспособить ее к имеющимся уже данным, проверить результат и достоверность модели и применить данную модель для прогнозирования.</p><h2 style="padding-top: 3pt;padding-left: 32pt;text-indent: 0pt;text-align: center;">Список использованных источников и литературы</h2><ol id="l5"><li data-list-text="1."><p class="s1" style="padding-top: 5pt;padding-left: 5pt;text-indent: 14pt;text-align: justify;">Иванова, Ю. В. <span class="s2">Нейронные сети и регрессионный анализ как метод про- гнозирования временных рядов / Ю. В. Иванова, Т. В. Черемисова // Academy. – 2017. – № 6 (21). – С. 46–48.</span></p></li><li data-list-text="2."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Благодатский, Г. А. <span class="s2">Нейронные сети как способ моделирования процес- сов / Г. А. Благодатский, М. М. Горохов, Л. Г. Саетова // Социально-эконо- мическое управление: теория и практика : науч.-практ. журн. – 2020. – № 4. – С. 60–64.</span></p></li><li data-list-text="3."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Щенников, В. Н. <span class="s2">Сравнение моделей с нейронной сетью и OLS-регрес- сией при построении стратегии управления риском от дохода по индексу / В. Н. Щенников, Е. В. Щенникова, С. А. Санников // Вестник МГУ. – 2017. –</span></p><p class="s2" style="padding-left: 5pt;text-indent: 0pt;line-height: 10pt;text-align: justify;">№ 1. – С. 12–20.</p></li><li data-list-text="4."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Санников, С. А. <span class="s2">Нейронные сети в задачах расчета цен опционов фондо- вых рынков // Вестник МГУ. – 2017. – № 1. – С. 21–26.</span></p></li><li data-list-text="5."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Ярушев, С. А. <span class="s2">Когнитивные гибридные системы поддержки принятия решений и прогнозирования / С. А. Ярушев, А. Н. Аверкин, В. Ю. Павлов // Программные продукты и системы. – 2017. – № 4. – С. 632–642.</span></p></li><li data-list-text="6."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Горохов, М. М. <span class="s2">Статистические методы анализа и обработки информа- ции: нейронные сети / М. М. Горохов, Л. Г. Саетова // Социально-экономи- ческое управление: теория и практика : науч.-практ. журн. – 2018. – № 4. – С. 192–195.</span></p></li><li data-list-text="7."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: left;">Мусин, А. Р. <span class="s2">Экономико-математическая модель прогнозирования дина- мики финансового рынка // Статистика и экономика. – 2018. – № 4. – URL: https://cyberleninka.ru/article/n/ekonomiko-matematicheskaya-model-prognozirova- niya-dinamiki-finansovogo-rynka (дата обращения: 19.12.2020).</span></p></li><li data-list-text="8."><p class="s1" style="padding-left: 5pt;text-indent: 14pt;text-align: justify;">Якупов, Д. Т. <span class="s2">Перспективы применения искусственных нейронных сетей для прогнозирования объемов грузоперевозок в транспортных системах / Д. Т. Якупов, О. Н. Рожко // Статистика и экономика. – 2017. – № 5. – С. 49–60.</span></p></li></ol></body></html>
